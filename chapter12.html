<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter 12: Bayesian Inference</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 50%, #667eea 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: rgba(255, 255, 255, 0.95);
            border-radius: 20px;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.15);
            overflow: hidden;
        }

        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 40px;
            text-align: center;
            position: relative;
            overflow: hidden;
        }

        .header::before {
            content: 'üß†‚öñÔ∏èüéØüìäüîÆ';
            position: absolute;
            top: 50%;
            left: -20%;
            transform: translateY(-50%);
            font-size: 4em;
            opacity: 0.1;
            animation: think 15s ease-in-out infinite;
        }

        @keyframes think {
            0%, 100% { left: -20%; opacity: 0.1; }
            50% { left: 120%; opacity: 0.2; }
        }

        .header h1 {
            position: relative;
            z-index: 1;
            font-size: 3em;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
        }

        .header p {
            position: relative;
            z-index: 1;
            font-size: 1.2em;
            opacity: 0.9;
        }

        .content {
            padding: 40px;
        }

        .section {
            margin-bottom: 40px;
            padding: 30px;
            border-radius: 15px;
            background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%);
            border-left: 5px solid #667eea;
            transition: all 0.3s ease;
            position: relative;
            overflow: hidden;
        }

        .section::before {
            content: '';
            position: absolute;
            top: -50%;
            right: -50%;
            width: 150px;
            height: 150px;
            background: radial-gradient(circle, rgba(102,126,234,0.1) 0%, transparent 70%);
            border-radius: 50%;
            animation: orbit 12s linear infinite;
        }

        @keyframes orbit {
            0% { transform: rotate(0deg) translateX(100px) rotate(0deg); }
            100% { transform: rotate(360deg) translateX(100px) rotate(-360deg); }
        }

        .section:hover {
            transform: translateY(-5px);
            box-shadow: 0 15px 30px rgba(102, 126, 234, 0.2);
        }

        .section h2 {
            color: #2c3e50;
            font-size: 2em;
            margin-bottom: 20px;
            border-bottom: 3px solid #667eea;
            padding-bottom: 10px;
            display: inline-block;
            position: relative;
            z-index: 1;
        }

        .section h3 {
            color: #34495e;
            font-size: 1.5em;
            margin: 25px 0 15px 0;
            background: linear-gradient(135deg, #667eea, #764ba2);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            position: relative;
            z-index: 1;
        }

        .bayes-box {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            border-radius: 15px;
            margin: 25px 0;
            box-shadow: 0 15px 30px rgba(102, 126, 234, 0.3);
            position: relative;
            text-align: center;
        }

        .bayes-box::before {
            content: '‚àù';
            position: absolute;
            top: 15px;
            right: 25px;
            font-size: 3em;
            opacity: 0.3;
            font-style: italic;
        }

        .bayes-box h4 {
            font-size: 1.5em;
            margin-bottom: 20px;
            border-bottom: 2px solid rgba(255,255,255,0.3);
            padding-bottom: 15px;
        }

        .formula-box {
            background: linear-gradient(135deg, #ffecd2 0%, #fcb69f 100%);
            padding: 20px;
            border-radius: 15px;
            margin: 15px 0;
            border: 2px solid #f39c12;
            font-family: 'Courier New', monospace;
            font-size: 1.1em;
            box-shadow: 0 8px 20px rgba(243, 156, 18, 0.2);
            position: relative;
            overflow: hidden;
        }

        .formula-box::before {
            content: 'œÄ(Œ∏|x)';
            position: absolute;
            top: 10px;
            right: 15px;
            font-size: 1.8em;
            opacity: 0.2;
            color: #d35400;
            font-style: italic;
        }

        .prior-posterior {
            display: grid;
            grid-template-columns: 1fr 1fr 1fr;
            gap: 20px;
            margin: 20px 0;
        }

        .distribution-card {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 25px;
            border-radius: 15px;
            box-shadow: 0 10px 25px rgba(102, 126, 234, 0.3);
            transition: all 0.3s ease;
            text-align: center;
        }

        .distribution-card:hover {
            transform: scale(1.05);
            box-shadow: 0 15px 30px rgba(102, 126, 234, 0.4);
        }

        .distribution-card h5 {
            font-size: 1.3em;
            margin-bottom: 15px;
            border-bottom: 2px solid rgba(255,255,255,0.3);
            padding-bottom: 10px;
        }

        .example-box {
            background: linear-gradient(135deg, #e0c3fc 0%, #9bb5ff 100%);
            padding: 25px;
            border-radius: 15px;
            margin: 15px 0;
            border: 2px solid #9c88ff;
            box-shadow: 0 8px 20px rgba(156, 136, 255, 0.2);
            position: relative;
        }

        .example-box h4 {
            color: #5a4fcf;
            margin-bottom: 15px;
            font-size: 1.3em;
        }

        .mcmc-box {
            background: linear-gradient(135deg, #ff6b6b 0%, #ee5a6f 100%);
            color: white;
            padding: 25px;
            border-radius: 15px;
            margin: 20px 0;
            box-shadow: 0 10px 20px rgba(255, 107, 107, 0.3);
            position: relative;
        }

        .mcmc-box::before {
            content: '‚õìÔ∏è';
            position: absolute;
            top: 15px;
            right: 20px;
            font-size: 2em;
            opacity: 0.7;
        }

        .mcmc-box h4 {
            font-size: 1.3em;
            margin-bottom: 15px;
            text-decoration: underline;
        }

        .algorithm-steps {
            background: linear-gradient(135deg, #ffecd2 0%, #fcb69f 100%);
            padding: 25px;
            border-radius: 15px;
            margin: 20px 0;
            border: 3px solid #f39c12;
        }

        .algorithm-step {
            background: rgba(255,255,255,0.7);
            margin: 10px 0;
            padding: 15px;
            border-radius: 10px;
            border-left: 4px solid #e67e22;
            font-weight: bold;
        }

        .highlight {
            background: linear-gradient(135deg, #ff9a9e 0%, #fecfef 100%);
            padding: 4px 10px;
            border-radius: 20px;
            font-weight: bold;
            color: #2c3e50;
            display: inline-block;
            margin: 2px;
        }

        .comparison-table {
            width: 100%;
            border-collapse: collapse;
            background: white;
            border-radius: 10px;
            overflow: hidden;
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
            margin: 20px 0;
        }

        .comparison-table th {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 15px;
            text-align: left;
        }

        .comparison-table td {
            padding: 12px 15px;
            border-bottom: 1px solid #eee;
        }

        .comparison-table tr:nth-child(even) {
            background: #f8f9fa;
        }

        .credible-interval {
            background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%);
            padding: 25px;
            border-radius: 15px;
            margin: 20px 0;
            border: 3px solid #26a69a;
            text-align: center;
        }

        .model-comparison {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        ul, ol {
            margin-left: 25px;
            margin-top: 10px;
        }

        li {
            margin-bottom: 8px;
        }

        .nav-buttons {
            display: flex;
            justify-content: space-between;
            padding: 30px 40px;
            background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%);
        }

        .nav-btn {
            padding: 12px 25px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            text-decoration: none;
            border-radius: 25px;
            font-weight: bold;
            transition: all 0.3s ease;
            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.3);
        }

        .nav-btn:hover {
            transform: translateY(-3px);
            box-shadow: 0 8px 20px rgba(102, 126, 234, 0.4);
        }

        @media (max-width: 768px) {
            .prior-posterior, .model-comparison {
                grid-template-columns: 1fr;
            }
            
            .header h1 {
                font-size: 2em;
            }
            
            .content {
                padding: 20px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>Chapter 12: Bayesian Inference</h1>
            <p>A Different Philosophy: Uncertainty as Probability</p>
        </div>

        <div class="content">
            <div class="section">
                <h2>üß† The Bayesian Paradigm</h2>
                <p>Bayesian inference treats parameters as random variables with probability distributions. This fundamentally different approach allows us to make probability statements about parameters directly!</p>
                
                <div class="example-box">
                    <h4>üåü Philosophical Difference</h4>
                    <p><strong>Frequentist:</strong> "Parameters are fixed, data is random"</p>
                    <p><strong>Bayesian:</strong> "Parameters are random, data is observed"</p>
                    <br>
                    <p><strong>Frequentist question:</strong> "What would happen if we repeated this experiment many times?"</p>
                    <p><strong>Bayesian question:</strong> "Given this specific data, what do we believe about the parameter?"</p>
                </div>

                <div class="bayes-box">
                    <h4>üéØ Bayes' Theorem - The Foundation</h4>
                    <div class="formula-box" style="background: rgba(255,255,255,0.2); border: 1px solid rgba(255,255,255,0.3);">
                        œÄ(Œ∏|x) = f(x|Œ∏)œÄ(Œ∏) / m(x)
                    </div>
                    <p><strong>In words:</strong></p>
                    <div class="formula-box" style="background: rgba(255,255,255,0.2); border: 1px solid rgba(255,255,255,0.3);">
                        Posterior ‚àù Likelihood √ó Prior
                    </div>
                </div>
            </div>

            <div class="section">
                <h2>üéØ Components of Bayesian Analysis</h2>

                <div class="prior-posterior">
                    <div class="distribution-card">
                        <h5>üìã Prior œÄ(Œ∏)</h5>
                        <p><strong>What we believe before seeing data</strong></p>
                        <ul>
                            <li>Subjective beliefs</li>
                            <li>Previous studies</li>
                            <li>Expert opinion</li>
                            <li>Mathematical convenience</li>
                        </ul>
                    </div>

                    <div class="distribution-card">
                        <h5>üìä Likelihood f(x|Œ∏)</h5>
                        <p><strong>Information from the data</strong></p>
                        <ul>
                            <li>Same as in frequentist approach</li>
                            <li>How likely is the data for each Œ∏?</li>
                            <li>Links data to parameter</li>
                        </ul>
                    </div>

                    <div class="distribution-card">
                        <h5>üéØ Posterior œÄ(Œ∏|x)</h5>
                        <p><strong>Updated beliefs after seeing data</strong></p>
                        <ul>
                            <li>Compromise between prior and data</li>
                            <li>Complete inference about Œ∏</li>
                            <li>Basis for all decisions</li>
                        </ul>
                    </div>
                </div>

                <div class="formula-box">
                    <strong>Marginal likelihood (normalizing constant):</strong>
                    <br>m(x) = ‚à´ f(x|Œ∏)œÄ(Œ∏) dŒ∏
                    <br><br>
                    <strong>Often ignore this:</strong> œÄ(Œ∏|x) ‚àù f(x|Œ∏)œÄ(Œ∏)
                </div>
            </div>

            <div class="section">
                <h2>üî¢ Simple Example: Binomial with Beta Prior</h2>

                <div class="example-box">
                    <h4>ü™ô Coin Flipping</h4>
                    <p><strong>Setup:</strong> Flip coin n times, observe x heads. Want to estimate Œ∏ = P(heads)</p>
                    
                    <p><strong>Likelihood:</strong> X|Œ∏ ~ Binomial(n, Œ∏)</p>
                    <div class="formula-box">
                        f(x|Œ∏) = C(n,x) Œ∏À£(1-Œ∏)‚Åø‚ÅªÀ£
                    </div>

                    <p><strong>Prior:</strong> Œ∏ ~ Beta(Œ±, Œ≤)</p>
                    <div class="formula-box">
                        œÄ(Œ∏) = [Œì(Œ±+Œ≤)/(Œì(Œ±)Œì(Œ≤))] Œ∏·µÖ‚Åª¬π(1-Œ∏)·µù‚Åª¬π
                    </div>

                    <p><strong>Posterior:</strong> Œ∏|x ~ Beta(Œ± + x, Œ≤ + n - x)</p>
                    <div class="formula-box">
                        œÄ(Œ∏|x) ‚àù Œ∏À£(1-Œ∏)‚Åø‚ÅªÀ£ √ó Œ∏·µÖ‚Åª¬π(1-Œ∏)·µù‚Åª¬π
                        <br>= Œ∏·µÖ‚Å∫À£‚Åª¬π(1-Œ∏)·µù‚Å∫‚Åø‚ÅªÀ£‚Åª¬π
                    </div>
                </div>

                <div class="bayes-box">
                    <h4>üåü Conjugate Priors</h4>
                    <p>When prior and posterior are in the same family, we call the prior <span class="highlight">conjugate</span></p>
                    <p><strong>Advantages:</strong></p>
                    <ul>
                        <li>Closed-form posteriors</li>
                        <li>Easy to compute</li>
                        <li>Interpretable parameters</li>
                        <li>Sequential updating</li>
                    </ul>
                    <table class="comparison-table" style="background: rgba(255,255,255,0.2);">
                        <tr>
                            <th>Likelihood</th>
                            <th>Conjugate Prior</th>
                            <th>Posterior</th>
                        </tr>
                        <tr>
                            <td>Binomial(n,Œ∏)</td>
                            <td>Beta(Œ±,Œ≤)</td>
                            <td>Beta(Œ±+x, Œ≤+n-x)</td>
                        </tr>
                        <tr>
                            <td>Normal(Œº,œÉ¬≤)</td>
                            <td>Normal(Œº‚ÇÄ,œÑ¬≤)</td>
                            <td>Normal(...)</td>
                        </tr>
                        <tr>
                            <td>Poisson(Œª)</td>
                            <td>Gamma(Œ±,Œ≤)</td>
                            <td>Gamma(Œ±+‚àëx, Œ≤+n)</td>
                        </tr>
                    </table>
                </div>
            </div>

            <div class="section">
                <h2>üìä Bayesian Point Estimation</h2>

                <div class="model-comparison">
                    <div class="distribution-card">
                        <h5>üìä Posterior Mean</h5>
                        <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                            Œ∏ÃÇ = E[Œ∏|x] = ‚à´ Œ∏œÄ(Œ∏|x) dŒ∏
                        </div>
                        <p><strong>Properties:</strong></p>
                        <ul>
                            <li>Minimizes squared error loss</li>
                            <li>Often close to MLE</li>
                            <li>Easy to interpret</li>
                        </ul>
                    </div>

                    <div class="distribution-card">
                        <h5>üìà Posterior Median</h5>
                        <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                            P(Œ∏ ‚â§ Œ∏ÃÇ|x) = 0.5
                        </div>
                        <p><strong>Properties:</strong></p>
                        <ul>
                            <li>Minimizes absolute error loss</li>
                            <li>Robust to outliers</li>
                            <li>50th percentile of posterior</li>
                        </ul>
                    </div>

                    <div class="distribution-card">
                        <h5>üéØ Posterior Mode (MAP)</h5>
                        <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                            Œ∏ÃÇ = argmax œÄ(Œ∏|x)
                        </div>
                        <p><strong>Properties:</strong></p>
                        <ul>
                            <li>Maximum A Posteriori</li>
                            <li>Minimizes 0-1 loss</li>
                            <li>Peak of posterior distribution</li>
                        </ul>
                    </div>
                </div>

                <div class="example-box">
                    <h4>ü™ô Coin Example Continued</h4>
                    <p><strong>Data:</strong> 20 flips, 12 heads</p>
                    <p><strong>Prior:</strong> Beta(2,2) (slightly favors Œ∏ = 0.5)</p>
                    <p><strong>Posterior:</strong> Beta(14, 10)</p>
                    
                    <div class="formula-box">
                        <strong>Posterior mean:</strong> 14/(14+10) = 14/24 = 0.583
                        <br><strong>MLE (for comparison):</strong> 12/20 = 0.6
                        <br><strong>Posterior pulls estimate toward prior belief!</strong>
                    </div>
                </div>
            </div>

            <div class="section">
                <h2>üìè Credible Intervals</h2>

                <div class="credible-interval">
                    <h4>üéØ Bayesian Confidence Intervals</h4>
                    <p>A <span class="highlight">100(1-Œ±)% credible interval</span> [L, U] satisfies:</p>
                    <div class="formula-box">
                        P(L ‚â§ Œ∏ ‚â§ U | x) = 1 - Œ±
                    </div>
                    <p><strong>Interpretation:</strong> "Given the data, there's a 95% probability Œ∏ is in this interval"</p>
                    <p><strong>This is what people think confidence intervals mean!</strong></p>
                </div>

                <div class="model-comparison">
                    <div class="example-box">
                        <h5>üìä Equal-Tailed Interval</h5>
                        <p>Put Œ±/2 probability in each tail</p>
                        <div class="formula-box">
                            [F‚Åª¬π(Œ±/2), F‚Åª¬π(1-Œ±/2)]
                        </div>
                        <p>where F is posterior CDF</p>
                    </div>

                    <div class="example-box">
                        <h5>üéØ Highest Posterior Density (HPD)</h5>
                        <p>Shortest interval with 1-Œ± probability</p>
                        <p><strong>Property:</strong> All points inside have higher density than points outside</p>
                        <p><strong>Advantage:</strong> Most "concentrated" belief</p>
                    </div>
                </div>
            </div>

            <div class="section">
                <h2>üß™ Bayesian Hypothesis Testing</h2>

                <div class="bayes-box">
                    <h4>‚öñÔ∏è Bayes Factors</h4>
                    <p>Compare two hypotheses H‚ÇÄ and H‚ÇÅ using:</p>
                    <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                        BF‚ÇÅ‚ÇÄ = m‚ÇÅ(x)/m‚ÇÄ(x) = P(x|H‚ÇÅ)/P(x|H‚ÇÄ)
                    </div>
                    <p><strong>Interpretation:</strong> How much more likely is the data under H‚ÇÅ vs H‚ÇÄ?</p>
                    
                    <table class="comparison-table" style="background: rgba(255,255,255,0.2);">
                        <tr>
                            <th>Bayes Factor</th>
                            <th>Evidence</th>
                        </tr>
                        <tr>
                            <td>1 - 3</td>
                            <td>Barely worth mentioning</td>
                        </tr>
                        <tr>
                            <td>3 - 10</td>
                            <td>Substantial</td>
                        </tr>
                        <tr>
                            <td>10 - 30</td>
                            <td>Strong</td>
                        </tr>
                        <tr>
                            <td>30 - 100</td>
                            <td>Very strong</td>
                        </tr>
                        <tr>
                            <td>> 100</td>
                            <td>Extreme</td>
                        </tr>
                    </table>
                </div>

                <div class="example-box">
                    <h4>üé≤ Testing Œ∏ = 0.5 vs Œ∏ ‚â† 0.5</h4>
                    <p><strong>Setup:</strong> Same coin example, test fairness</p>
                    <p><strong>H‚ÇÄ:</strong> Œ∏ = 0.5 (fair coin)</p>
                    <p><strong>H‚ÇÅ:</strong> Œ∏ ~ Beta(1,1) (any value equally likely)</p>
                    
                    <div class="formula-box">
                        BF‚ÇÅ‚ÇÄ = [‚à´‚ÇÄ¬π f(x|Œ∏)œÄ‚ÇÅ(Œ∏) dŒ∏] / f(x|Œ∏=0.5)
                        <br><br>
                        For our data (12 heads in 20 flips):
                        <br>BF‚ÇÅ‚ÇÄ ‚âà 0.7 (slight evidence for H‚ÇÄ)
                    </div>
                </div>
            </div>

            <div class="section">
                <h2>‚õìÔ∏è Markov Chain Monte Carlo (MCMC)</h2>

                <div class="mcmc-box">
                    <h4>üéØ When Conjugacy Fails</h4>
                    <p>Most real problems don't have conjugate priors or closed-form posteriors</p>
                    <p><strong>Solution:</strong> Sample from the posterior distribution!</p>
                    <p><strong>MCMC:</strong> Construct a Markov chain whose stationary distribution is œÄ(Œ∏|x)</p>
                </div>

                <h3>Metropolis-Hastings Algorithm</h3>
                <div class="algorithm-steps">
                    <h4>üîÑ Algorithm Steps</h4>
                    <div class="algorithm-step">
                        <strong>Step 1:</strong> Start with initial value Œ∏‚ÅΩ‚Å∞‚Åæ
                    </div>
                    <div class="algorithm-step">
                        <strong>Step 2:</strong> Propose new value Œ∏* from q(Œ∏*|Œ∏‚ÅΩ·µè‚Åæ)
                    </div>
                    <div class="algorithm-step">
                        <strong>Step 3:</strong> Compute acceptance probability Œ± = min{1, [œÄ(Œ∏*)q(Œ∏‚ÅΩ·µè‚Åæ|Œ∏*)]/[œÄ(Œ∏‚ÅΩ·µè‚Åæ)q(Œ∏*|Œ∏‚ÅΩ·µè‚Åæ)]}
                    </div>
                    <div class="algorithm-step">
                        <strong>Step 4:</strong> Accept Œ∏‚ÅΩ·µè‚Å∫¬π‚Åæ = Œ∏* with probability Œ±, otherwise Œ∏‚ÅΩ·µè‚Å∫¬π‚Åæ = Œ∏‚ÅΩ·µè‚Åæ
                    </div>
                    <div class="algorithm-step">
                        <strong>Step 5:</strong> Repeat steps 2-4
                    </div>
                </div>

                <div class="example-box">
                    <h4>üéØ Special Cases</h4>
                    <p><strong>Random Walk Metropolis:</strong> q(Œ∏*|Œ∏) = N(Œ∏, œÉ¬≤I)</p>
                    <ul>
                        <li>Simple to implement</li>
                        <li>Acceptance rate depends on œÉ</li>
                        <li>Optimal acceptance rate ‚âà 45% (1D) or 23% (high-D)</li>
                    </ul>
                    
                    <p><strong>Gibbs Sampling:</strong> Sample each component conditionally</p>
                    <ul>
                        <li>Always accept (when possible)</li>
                        <li>Requires conditional distributions</li>
                        <li>Very effective for hierarchical models</li>
                    </ul>
                </div>
            </div>

            <div class="section">
                <h2>üèóÔ∏è Hierarchical Models</h2>

                <div class="bayes-box">
                    <h4>üéØ Multi-Level Structure</h4>
                    <p>Model parameters as having their own prior distributions with hyperparameters</p>
                    <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                        <strong>Level 1:</strong> x·µ¢|Œ∏·µ¢ ~ f(x·µ¢|Œ∏·µ¢)
                        <br><strong>Level 2:</strong> Œ∏·µ¢|œÜ ~ œÄ(Œ∏·µ¢|œÜ)
                        <br><strong>Level 3:</strong> œÜ ~ œÄ(œÜ)
                    </div>
                    <p><strong>Advantage:</strong> "Borrows strength" across groups</p>
                </div>

                <div class="example-box">
                    <h4>üè´ School Example</h4>
                    <p><strong>Problem:</strong> Estimate effect of coaching on SAT scores in J schools</p>
                    
                    <p><strong>Data:</strong> y‚±º = observed effect in school j, œÉ‚±º = standard error</p>
                    <p><strong>Model:</strong></p>
                    <div class="formula-box">
                        y‚±º|Œ∏‚±º ~ N(Œ∏‚±º, œÉ‚±º¬≤)  (known œÉ‚±º)
                        <br>Œ∏‚±º|Œº,œÑ ~ N(Œº, œÑ¬≤)  (exchangeable effects)
                        <br>Œº ~ N(0, 100¬≤)  (vague prior)
                        <br>œÑ ~ Half-Cauchy(0, 25)  (weakly informative)
                    </div>
                    
                    <p><strong>Result:</strong> Extreme school effects "shrink" toward overall mean</p>
                    <p><strong>Benefit:</strong> Better predictions than treating schools independently</p>
                </div>
            </div>

            <div class="section">
                <h2>üìä Model Comparison</h2>

                <div class="model-comparison">
                    <div class="distribution-card">
                        <h5>üìè Deviance Information Criterion (DIC)</h5>
                        <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                            DIC = DÃÑ + pD
                        </div>
                        <p><strong>DÃÑ:</strong> Posterior mean deviance</p>
                        <p><strong>pD:</strong> Effective number of parameters</p>
                        <p><strong>Use:</strong> Lower DIC is better</p>
                    </div>

                    <div class="distribution-card">
                        <h5>üìà Watanabe-Akaike IC (WAIC)</h5>
                        <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                            WAIC = -2‚àë·µ¢ log p(y·µ¢|y‚Çã·µ¢)
                        </div>
                        <p><strong>Approximates:</strong> Leave-one-out cross-validation</p>
                        <p><strong>Advantage:</strong> Fully Bayesian, no point estimates</p>
                    </div>

                    <div class="distribution-card">
                        <h5>üéØ Leave-One-Out CV (LOO)</h5>
                        <p><strong>Gold standard:</strong> Actual predictive performance</p>
                        <p><strong>Efficient approximation:</strong> Pareto smoothed importance sampling</p>
                        <p><strong>Software:</strong> loo package in R</p>
                    </div>
                </div>
            </div>

            <div class="section">
                <h2>‚öñÔ∏è Frequentist vs Bayesian</h2>

                <table class="comparison-table">
                    <tr>
                        <th>Aspect</th>
                        <th>Frequentist</th>
                        <th>Bayesian</th>
                    </tr>
                    <tr>
                        <td><strong>Parameters</strong></td>
                        <td>Fixed but unknown</td>
                        <td>Random variables</td>
                    </tr>
                    <tr>
                        <td><strong>Probability</strong></td>
                        <td>Long-run frequency</td>
                        <td>Degree of belief</td>
                    </tr>
                    <tr>
                        <td><strong>Inference</strong></td>
                        <td>Sampling distribution</td>
                        <td>Posterior distribution</td>
                    </tr>
                    <tr>
                        <td><strong>Intervals</strong></td>
                        <td>Confidence intervals</td>
                        <td>Credible intervals</td>
                    </tr>
                    <tr>
                        <td><strong>Model Selection</strong></td>
                        <td>Hypothesis testing</td>
                        <td>Bayes factors, model averaging</td>
                    </tr>
                    <tr>
                        <td><strong>Computation</strong></td>
                        <td>Often analytical</td>
                        <td>Often simulation-based</td>
                    </tr>
                </table>
            </div>

            <div class="section">
                <h2>‚ö†Ô∏è Common Pitfalls</h2>

                <div class="model-comparison">
                    <div class="mcmc-box" style="background: linear-gradient(135deg, #ff6b6b 0%, #ee5a6f 100%);">
                        <h4>‚ùå Prior sensitivity</h4>
                        <p><strong>Problem:</strong> Results may depend heavily on prior choice</p>
                        <p><strong>Solution:</strong> Sensitivity analysis with different priors</p>
                        <p><strong>Tip:</strong> Use weakly informative priors when possible</p>
                    </div>

                    <div class="mcmc-box" style="background: linear-gradient(135deg, #ff6b6b 0%, #ee5a6f 100%);">
                        <h4>‚ùå MCMC diagnostics ignored</h4>
                        <p><strong>Problem:</strong> Chain may not have converged</p>
                        <p><strong>Check:</strong> Trace plots, RÃÇ statistic, effective sample size</p>
                        <p><strong>Rule:</strong> Always check convergence!</p>
                    </div>

                    <div class="mcmc-box" style="background: linear-gradient(135deg, #ff6b6b 0%, #ee5a6f 100%);">
                        <h4>‚ùå Interpreting credible intervals as confidence intervals</h4>
                        <p><strong>Different meanings!</strong> Credible intervals have direct probability interpretation</p>
                        <p><strong>Advantage:</strong> More intuitive interpretation</p>
                    </div>
                </div>
            </div>

            <div class="section">
                <h2>üöÄ Modern Bayesian Tools</h2>

                <div class="example-box">
                    <h4>üíª Software Ecosystem</h4>
                    <p><strong>Stan:</strong> Probabilistic programming language with HMC</p>
                    <p><strong>PyMC:</strong> Python library for Bayesian modeling</p>
                    <p><strong>JAGS/BUGS:</strong> Gibbs sampling for hierarchical models</p>
                    <p><strong>Edward/TensorFlow Probability:</strong> Deep learning + Bayesian</p>
                    
                    <div class="formula-box">
                        <strong>Key advantages:</strong>
                        <br>‚Ä¢ Automatic differentiation
                        <br>‚Ä¢ Efficient sampling algorithms
                        <br>‚Ä¢ Model checking tools
                        <br>‚Ä¢ Easy specification of complex models
                    </div>
                </div>

                <div class="bayes-box">
                    <h4>üéØ Why Bayesian Methods Are Growing</h4>
                    <ul>
                        <li><strong>Computational revolution:</strong> MCMC makes complex models feasible</li>
                        <li><strong>Natural uncertainty quantification:</strong> Full posterior distributions</li>
                        <li><strong>Flexible modeling:</strong> Hierarchical and mixture models</li>
                        <li><strong>Prior information:</strong> Can incorporate domain knowledge</li>
                        <li><strong>Decision theory:</strong> Natural framework for decision making</li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="nav-buttons">
            <a href="#" class="nav-btn">‚Üê Chapter 11: Hypothesis Testing</a>
            <a href="#" class="nav-btn">Chapter 13: Decision Theory ‚Üí</a>
        </div>
    </div>
</body>
</html>