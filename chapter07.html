<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter 7: Statistical Inference</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            background: linear-gradient(135deg, #a8edea 0%, #fed6e3 50%, #a8edea 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: rgba(255, 255, 255, 0.95);
            border-radius: 20px;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.15);
            overflow: hidden;
        }

        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 40px;
            text-align: center;
            position: relative;
            overflow: hidden;
        }

        .header::before {
            content: 'üéØüìäüìàüîçüìâ';
            position: absolute;
            top: 50%;
            left: -30%;
            transform: translateY(-50%);
            font-size: 4em;
            opacity: 0.1;
            animation: drift 20s linear infinite;
        }

        @keyframes drift {
            0% { left: -30%; }
            100% { left: 130%; }
        }

        .header h1 {
            position: relative;
            z-index: 1;
            font-size: 3em;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
        }

        .header p {
            position: relative;
            z-index: 1;
            font-size: 1.2em;
            opacity: 0.9;
        }

        .content {
            padding: 40px;
        }

        .section {
            margin-bottom: 40px;
            padding: 30px;
            border-radius: 15px;
            background: linear-gradient(135deg, #ffecd2 0%, #fcb69f 100%);
            border-left: 5px solid #667eea;
            transition: all 0.3s ease;
            position: relative;
            overflow: hidden;
        }

        .section::before {
            content: '';
            position: absolute;
            top: 0;
            right: 0;
            width: 100px;
            height: 100px;
            background: radial-gradient(circle, rgba(102,126,234,0.1) 0%, transparent 70%);
            border-radius: 50%;
            animation: bubble 8s ease-in-out infinite;
        }

        @keyframes bubble {
            0%, 100% { transform: translate(20px, 20px) scale(1); }
            50% { transform: translate(-20px, -20px) scale(1.2); }
        }

        .section:hover {
            transform: translateY(-5px);
            box-shadow: 0 15px 30px rgba(102, 126, 234, 0.2);
        }

        .section h2 {
            color: #2c3e50;
            font-size: 2em;
            margin-bottom: 20px;
            border-bottom: 3px solid #667eea;
            padding-bottom: 10px;
            display: inline-block;
            position: relative;
            z-index: 1;
        }

        .section h3 {
            color: #34495e;
            font-size: 1.5em;
            margin: 25px 0 15px 0;
            background: linear-gradient(135deg, #667eea, #764ba2);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            position: relative;
            z-index: 1;
        }

        .method-card {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 25px;
            border-radius: 15px;
            margin: 20px 0;
            box-shadow: 0 10px 25px rgba(102, 126, 234, 0.3);
            transition: all 0.3s ease;
            position: relative;
        }

        .method-card::before {
            content: 'üéØ';
            position: absolute;
            top: 15px;
            right: 20px;
            font-size: 2em;
            opacity: 0.3;
        }

        .method-card:hover {
            transform: scale(1.02);
            box-shadow: 0 15px 30px rgba(102, 126, 234, 0.4);
        }

        .method-card h4 {
            font-size: 1.4em;
            margin-bottom: 15px;
            border-bottom: 2px solid rgba(255,255,255,0.3);
            padding-bottom: 10px;
        }

        .formula-box {
            background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%);
            padding: 20px;
            border-radius: 15px;
            margin: 15px 0;
            border: 2px solid #26a69a;
            font-family: 'Courier New', monospace;
            font-size: 1.1em;
            box-shadow: 0 8px 20px rgba(38, 166, 154, 0.2);
            position: relative;
            overflow: hidden;
        }

        .formula-box::before {
            content: '‚àÇ/‚àÇŒ∏';
            position: absolute;
            top: 10px;
            right: 15px;
            font-size: 2em;
            opacity: 0.2;
            color: #26a69a;
            font-style: italic;
        }

        .example-box {
            background: linear-gradient(135deg, #e0c3fc 0%, #9bb5ff 100%);
            padding: 25px;
            border-radius: 15px;
            margin: 15px 0;
            border: 2px solid #9c88ff;
            box-shadow: 0 8px 20px rgba(156, 136, 255, 0.2);
            position: relative;
        }

        .example-box h4 {
            color: #5a4fcf;
            margin-bottom: 15px;
            font-size: 1.3em;
        }

        .theorem-box {
            background: linear-gradient(135deg, #ff6b6b 0%, #ee5a6f 100%);
            color: white;
            padding: 25px;
            border-radius: 15px;
            margin: 20px 0;
            box-shadow: 0 10px 20px rgba(255, 107, 107, 0.3);
            position: relative;
        }

        .theorem-box::before {
            content: '‚àÄŒ∏‚ààŒò';
            position: absolute;
            top: 15px;
            right: 20px;
            font-size: 1.5em;
            opacity: 0.7;
            font-style: italic;
        }

        .theorem-box h4 {
            font-size: 1.3em;
            margin-bottom: 15px;
            text-decoration: underline;
        }

        .highlight {
            background: linear-gradient(135deg, #ff9a9e 0%, #fecfef 100%);
            padding: 4px 10px;
            border-radius: 20px;
            font-weight: bold;
            color: #2c3e50;
            display: inline-block;
            margin: 2px;
        }

        .property-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .property-card {
            background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%);
            padding: 20px;
            border-radius: 15px;
            border: 2px solid #26a69a;
            box-shadow: 0 5px 15px rgba(38, 166, 154, 0.2);
        }

        .property-card h5 {
            color: #2c3e50;
            margin-bottom: 10px;
            font-size: 1.2em;
        }

        .comparison-table {
            width: 100%;
            border-collapse: collapse;
            background: white;
            border-radius: 10px;
            overflow: hidden;
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
            margin: 20px 0;
        }

        .comparison-table th {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 15px;
            text-align: left;
        }

        .comparison-table td {
            padding: 12px 15px;
            border-bottom: 1px solid #eee;
        }

        .comparison-table tr:nth-child(even) {
            background: #f8f9fa;
        }

        .estimator-comparison {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .bootstrap-demo {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 25px;
            border-radius: 15px;
            margin: 20px 0;
            text-align: center;
        }

        .bootstrap-step {
            background: rgba(255,255,255,0.2);
            margin: 10px 0;
            padding: 15px;
            border-radius: 10px;
            border-left: 4px solid rgba(255,255,255,0.5);
        }

        ul, ol {
            margin-left: 25px;
            margin-top: 10px;
        }

        li {
            margin-bottom: 8px;
        }

        .nav-buttons {
            display: flex;
            justify-content: space-between;
            padding: 30px 40px;
            background: linear-gradient(135deg, #ffecd2 0%, #fcb69f 100%);
        }

        .nav-btn {
            padding: 12px 25px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            text-decoration: none;
            border-radius: 25px;
            font-weight: bold;
            transition: all 0.3s ease;
            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.3);
        }

        .nav-btn:hover {
            transform: translateY(-3px);
            box-shadow: 0 8px 20px rgba(102, 126, 234, 0.4);
        }

        @media (max-width: 768px) {
            .property-grid, .estimator-comparison {
                grid-template-columns: 1fr;
            }
            
            .header h1 {
                font-size: 2em;
            }
            
            .content {
                padding: 20px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>Chapter 7: Statistical Inference</h1>
            <p>From Data to Decisions: Estimation and Testing</p>
        </div>

        <div class="content">
            <div class="section">
                <h2>üéØ What is Statistical Inference?</h2>
                <p>Statistical inference is the process of using sample data to make conclusions about population parameters. It's the bridge between data and decision-making!</p>
                
                <div class="example-box">
                    <h4>üåü Real-World Example</h4>
                    <p><strong>Drug Trial:</strong> Test new medication on 1000 patients, observe 85% improvement rate</p>
                    <p><strong>Questions:</strong></p>
                    <ul>
                        <li>What's our best estimate of the true improvement rate?</li>
                        <li>How confident can we be in this estimate?</li>
                        <li>Is this significantly better than the 75% rate of current treatment?</li>
                    </ul>
                    <p><strong>Statistical inference provides the tools to answer these questions!</strong></p>
                </div>

                <div class="property-grid">
                    <div class="property-card">
                        <h5>üéØ Point Estimation</h5>
                        <p>Find single "best guess" for unknown parameter</p>
                        <p><strong>Example:</strong> Sample mean XÃÑ estimates population mean Œº</p>
                    </div>
                    <div class="property-card">
                        <h5>üìè Interval Estimation</h5>
                        <p>Find range of plausible values for parameter</p>
                        <p><strong>Example:</strong> 95% confidence interval</p>
                    </div>
                    <div class="property-card">
                        <h5>üß™ Hypothesis Testing</h5>
                        <p>Test claims about population parameters</p>
                        <p><strong>Example:</strong> Is new drug better than old?</p>
                    </div>
                </div>
            </div>

            <div class="section">
                <h2>üéØ Point Estimation</h2>

                <h3>Properties of Estimators</h3>
                <div class="property-grid">
                    <div class="property-card">
                        <h5>üéØ Unbiasedness</h5>
                        <div class="formula-box" style="font-size: 0.9em;">
                            E[Œ∏ÃÇ] = Œ∏
                        </div>
                        <p>Estimator hits the target on average</p>
                        <p><strong>Example:</strong> Sample mean is unbiased for population mean</p>
                    </div>

                    <div class="property-card">
                        <h5>üîí Consistency</h5>
                        <div class="formula-box" style="font-size: 0.9em;">
                            Œ∏ÃÇ‚Çô ‚Üí·µñ Œ∏
                        </div>
                        <p>Estimator gets closer to truth as n increases</p>
                        <p><strong>Good news:</strong> Most reasonable estimators are consistent</p>
                    </div>

                    <div class="property-card">
                        <h5>‚ö° Efficiency</h5>
                        <div class="formula-box" style="font-size: 0.9em;">
                            Var(Œ∏ÃÇ) = minimum possible
                        </div>
                        <p>Among unbiased estimators, has smallest variance</p>
                        <p><strong>Gold standard:</strong> Achieves Cram√©r-Rao lower bound</p>
                    </div>
                </div>

                <div class="theorem-box">
                    <h4>üèÜ Cram√©r-Rao Lower Bound</h4>
                    <p>For any unbiased estimator Œ∏ÃÇ of parameter Œ∏:</p>
                    <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                        Var(Œ∏ÃÇ) ‚â• 1/I(Œ∏)
                    </div>
                    <p>where I(Œ∏) is the Fisher Information:</p>
                    <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                        I(Œ∏) = E[(‚àÇlog f/‚àÇŒ∏)¬≤] = -E[‚àÇ¬≤log f/‚àÇŒ∏¬≤]
                    </div>
                    <p><strong>Interpretation:</strong> There's a fundamental limit to how precisely we can estimate!</p>
                </div>
            </div>

            <div class="section">
                <h2>üîç Methods of Estimation</h2>

                <div class="estimator-comparison">
                    <div class="method-card">
                        <h4>üìä Method of Moments</h4>
                        <p><strong>Idea:</strong> Equate sample moments to population moments</p>
                        <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                            (1/n)‚àëX·µ¢·µè = E[X·µè]
                        </div>
                        <p><strong>Pros:</strong></p>
                        <ul>
                            <li>Simple and intuitive</li>
                            <li>Always exists</li>
                            <li>Consistent under mild conditions</li>
                        </ul>
                        <p><strong>Cons:</strong></p>
                        <ul>
                            <li>May not be efficient</li>
                            <li>Can give nonsensical answers</li>
                        </ul>
                    </div>

                    <div class="method-card">
                        <h4>üéØ Maximum Likelihood</h4>
                        <p><strong>Idea:</strong> Find parameter that makes observed data most likely</p>
                        <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                            Œ∏ÃÇ‚Çò‚Çó‚Çë = argmax L(Œ∏) = argmax ‚àèf(x·µ¢; Œ∏)
                        </div>
                        <p><strong>Pros:</strong></p>
                        <ul>
                            <li>Asymptotically efficient</li>
                            <li>Invariant under reparameterization</li>
                            <li>Asymptotically normal</li>
                        </ul>
                        <p><strong>Cons:</strong></p>
                        <ul>
                            <li>May not have closed form</li>
                            <li>Can be biased in small samples</li>
                        </ul>
                    </div>

                    <div class="method-card">
                        <h4>üìê Least Squares</h4>
                        <p><strong>Idea:</strong> Minimize sum of squared residuals</p>
                        <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                            Œ∏ÃÇ‚Çó‚Çõ = argmin ‚àë(y·µ¢ - g(x·µ¢; Œ∏))¬≤
                        </div>
                        <p><strong>Special case:</strong> Linear regression</p>
                        <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                            Œ≤ÃÇ = (X'X)‚Åª¬πX'Y
                        </div>
                        <p><strong>Advantages:</strong></p>
                        <ul>
                            <li>Closed form solution (linear case)</li>
                            <li>BLUE under Gauss-Markov conditions</li>
                            <li>Doesn't require distributional assumptions</li>
                        </ul>
                    </div>
                </div>
            </div>

            <div class="section">
                <h2>üìä Maximum Likelihood in Detail</h2>

                <div class="theorem-box">
                    <h4>üåü Asymptotic Properties of MLE</h4>
                    <p>Under regularity conditions, the MLE Œ∏ÃÇ‚Çò‚Çó‚Çë has:</p>
                    <ol>
                        <li><strong>Consistency:</strong> Œ∏ÃÇ‚Çò‚Çó‚Çë ‚Üí·µñ Œ∏‚ÇÄ</li>
                        <li><strong>Asymptotic Normality:</strong> ‚àön(Œ∏ÃÇ‚Çò‚Çó‚Çë - Œ∏‚ÇÄ) ‚áí N(0, I‚Åª¬π(Œ∏‚ÇÄ))</li>
                        <li><strong>Efficiency:</strong> Achieves Cram√©r-Rao bound asymptotically</li>
                        <li><strong>Invariance:</strong> If Œ∏ÃÇ is MLE of Œ∏, then g(Œ∏ÃÇ) is MLE of g(Œ∏)</li>
                    </ol>
                </div>

                <div class="example-box">
                    <h4>ü™ô Example: Binomial Parameter</h4>
                    <p><strong>Setup:</strong> X‚ÇÅ, ..., X‚Çô ~ Bernoulli(p), want to estimate p</p>
                    <p><strong>Likelihood:</strong></p>
                    <div class="formula-box">
                        L(p) = ‚àèpÀ£‚Å±(1-p)¬π‚ÅªÀ£‚Å± = p^‚àëx·µ¢(1-p)‚Åø‚Åª^‚àëx·µ¢
                    </div>
                    <p><strong>Log-likelihood:</strong></p>
                    <div class="formula-box">
                        ‚Ñì(p) = (‚àëx·µ¢)log p + (n-‚àëx·µ¢)log(1-p)
                    </div>
                    <p><strong>Score function:</strong></p>
                    <div class="formula-box">
                        ‚àÇ‚Ñì/‚àÇp = ‚àëx·µ¢/p - (n-‚àëx·µ¢)/(1-p) = 0
                    </div>
                    <p><strong>MLE solution:</strong></p>
                    <div class="formula-box">
                        pÃÇ‚Çò‚Çó‚Çë = (‚àëx·µ¢)/n = XÃÑ
                    </div>
                    <p><strong>Result:</strong> Sample proportion is MLE! (And it's unbiased and efficient)</p>
                </div>
            </div>

            <div class="section">
                <h2>üìè Confidence Intervals</h2>

                <div class="theorem-box">
                    <h4>üéØ Definition</h4>
                    <p>A <span class="highlight">confidence interval</span> [L(X), U(X)] has <span class="highlight">coverage probability</span>:</p>
                    <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                        P(L(X) ‚â§ Œ∏ ‚â§ U(X)) ‚â• 1 - Œ± for all Œ∏ ‚àà Œò
                    </div>
                    <p><strong>Interpretation:</strong> In repeated sampling, (1-Œ±)√ó100% of intervals contain the true parameter</p>
                </div>

                <div class="example-box">
                    <h4>üå°Ô∏è Normal Mean Example (œÉ known)</h4>
                    <p><strong>Setup:</strong> X‚ÇÅ, ..., X‚Çô ~ N(Œº, œÉ¬≤), œÉ known, want CI for Œº</p>
                    <p><strong>Pivotal quantity:</strong></p>
                    <div class="formula-box">
                        Z = (XÃÑ - Œº)/(œÉ/‚àön) ~ N(0,1)
                    </div>
                    <p><strong>Probability statement:</strong></p>
                    <div class="formula-box">
                        P(-z_{Œ±/2} ‚â§ Z ‚â§ z_{Œ±/2}) = 1 - Œ±
                    </div>
                    <p><strong>Rearranging:</strong></p>
                    <div class="formula-box">
                        P(XÃÑ - z_{Œ±/2}œÉ/‚àön ‚â§ Œº ‚â§ XÃÑ + z_{Œ±/2}œÉ/‚àön) = 1 - Œ±
                    </div>
                    <p><strong>95% CI:</strong> XÃÑ ¬± 1.96œÉ/‚àön</p>
                </div>

                <div class="property-grid">
                    <div class="property-card">
                        <h5>üìê Pivotal Method</h5>
                        <p>Find quantity Q(X,Œ∏) with known distribution</p>
                        <p>Invert probability statement to get CI</p>
                    </div>
                    <div class="property-card">
                        <h5>üéØ Asymptotic CIs</h5>
                        <p>Use CLT: Œ∏ÃÇ ‚âà N(Œ∏, œÉ¬≤/n)</p>
                        <p>CI: Œ∏ÃÇ ¬± z_{Œ±/2}œÉÃÇ/‚àön</p>
                    </div>
                    <div class="property-card">
                        <h5>üìä Likelihood-based</h5>
                        <p>Use asymptotic distribution of likelihood ratio</p>
                        <p>More complex but very general</p>
                    </div>
                </div>
            </div>

            <div class="section">
                <h2>üîÑ Bootstrap Methods</h2>

                <div class="bootstrap-demo">
                    <h4>üéØ Bootstrap Principle</h4>
                    <p><strong>"The bootstrap is a computer-based method for assigning measures of accuracy to statistical estimates"</strong></p>
                    
                    <div class="bootstrap-step">
                        <strong>Step 1:</strong> Resample with replacement from original data
                    </div>
                    <div class="bootstrap-step">
                        <strong>Step 2:</strong> Calculate statistic for each bootstrap sample
                    </div>
                    <div class="bootstrap-step">
                        <strong>Step 3:</strong> Use distribution of bootstrap statistics to estimate sampling distribution
                    </div>
                </div>

                <div class="example-box">
                    <h4>üé≤ Bootstrap Confidence Interval</h4>
                    <p><strong>Original sample:</strong> {x‚ÇÅ, x‚ÇÇ, ..., x‚Çô}</p>
                    <p><strong>Bootstrap samples:</strong> {x‚ÇÅ*, x‚ÇÇ*, ..., x‚Çô*} (sampled with replacement)</p>
                    <p><strong>Bootstrap statistics:</strong> T‚ÇÅ*, T‚ÇÇ*, ..., T_B*</p>
                    <p><strong>Percentile CI:</strong> [T*_{(Œ±/2)}, T*_{(1-Œ±/2)}]</p>
                    
                    <div class="formula-box">
                        <strong>Example with B = 1000 bootstrap samples:</strong>
                        <br>95% CI = [T*‚Çç‚ÇÇ‚ÇÖ‚Çé, T*‚Çç‚Çâ‚Çá‚ÇÖ‚Çé]
                        <br>(25th and 975th order statistics)
                    </div>
                </div>

                <div class="theorem-box">
                    <h4>üéØ When Bootstrap Works</h4>
                    <p><strong>Advantages:</strong></p>
                    <ul>
                        <li>No distributional assumptions</li>
                        <li>Works for complex statistics</li>
                        <li>Provides automatic bias correction</li>
                        <li>Easy to implement</li>
                    </ul>
                    <p><strong>Limitations:</strong></p>
                    <ul>
                        <li>Computationally intensive</li>
                        <li>May fail for extreme order statistics</li>
                        <li>Assumes sample is representative</li>
                    </ul>
                </div>
            </div>

            <div class="section">
                <h2>üìä Sufficient Statistics</h2>

                <div class="theorem-box">
                    <h4>üéØ Definition and Intuition</h4>
                    <p>T(X) is <span class="highlight">sufficient</span> for Œ∏ if the conditional distribution of X given T(X) doesn't depend on Œ∏</p>
                    <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                        P(X = x | T(X) = t, Œ∏) doesn't depend on Œ∏
                    </div>
                    <p><strong>Intuition:</strong> T(X) contains all the information about Œ∏ that's in the data!</p>
                </div>

                <div class="theorem-box">
                    <h4>üìã Factorization Theorem</h4>
                    <p>T(X) is sufficient for Œ∏ if and only if:</p>
                    <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                        f(x; Œ∏) = g(T(x); Œ∏) √ó h(x)
                    </div>
                    <p>where g depends on Œ∏ and h doesn't.</p>
                </div>

                <div class="example-box">
                    <h4>üîî Normal Distribution Example</h4>
                    <p><strong>Case 1:</strong> Œº unknown, œÉ¬≤ known</p>
                    <p><strong>Sufficient statistic:</strong> T(X) = XÃÑ (sample mean)</p>
                    
                    <p><strong>Case 2:</strong> Both Œº and œÉ¬≤ unknown</p>
                    <p><strong>Sufficient statistic:</strong> T(X) = (XÃÑ, ‚àëX·µ¢¬≤) (mean and sum of squares)</p>
                    
                    <div class="formula-box">
                        <strong>Why sufficient?</strong> All we need from the data to estimate Œº and œÉ¬≤ 
                        are the sample mean and sample variance!
                    </div>
                </div>

                <div class="theorem-box">
                    <h4>üèÜ Rao-Blackwell Theorem</h4>
                    <p>If T is sufficient and Œ∏ÃÇ is unbiased, then:</p>
                    <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                        Œ∏ÃÇ* = E[Œ∏ÃÇ|T] is unbiased with Var(Œ∏ÃÇ*) ‚â§ Var(Œ∏ÃÇ)
                    </div>
                    <p><strong>Message:</strong> We can always improve an estimator by conditioning on a sufficient statistic!</p>
                </div>
            </div>

            <div class="section">
                <h2>üéØ Completeness and Optimality</h2>

                <div class="theorem-box">
                    <h4>üîí Complete Statistics</h4>
                    <p>T is <span class="highlight">complete</span> if E[g(T)] = 0 for all Œ∏ implies g(T) = 0 almost surely</p>
                    <p><strong>Intuition:</strong> No non-trivial function of T has expected value zero</p>
                </div>

                <div class="theorem-box">
                    <h4>üèÜ Lehmann-Scheff√© Theorem</h4>
                    <p>If T is complete and sufficient, and Œ∏ÃÇ is unbiased, then E[Œ∏ÃÇ|T] is the unique UMVU estimator</p>
                    <p><strong>UMVU:</strong> Uniformly Minimum Variance Unbiased</p>
                    <p><strong>Practical importance:</strong> Gives us the "best" unbiased estimator!</p>
                </div>

                <div class="example-box">
                    <h4>üìä Exponential Family</h4>
                    <p>For canonical exponential families:</p>
                    <div class="formula-box">
                        f(x; Œ∏) = h(x)exp{Œ∏·µÄT(x) - A(Œ∏)}
                    </div>
                    <ul>
                        <li><strong>T(X) is sufficient</strong></li>
                        <li><strong>T(X) is complete</strong> (if parameter space contains open set)</li>
                        <li><strong>‚àáA(Œ∏) is UMVU estimator</strong> of E[T(X)]</li>
                    </ul>
                </div>
            </div>

            <div class="section">
                <h2>üß™ Hypothesis Testing Preview</h2>

                <div class="example-box">
                    <h4>üéØ Basic Framework</h4>
                    <p><strong>Null hypothesis H‚ÇÄ:</strong> Default assumption (e.g., "no effect")</p>
                    <p><strong>Alternative hypothesis H‚ÇÅ:</strong> What we're testing for</p>
                    <p><strong>Test statistic:</strong> Function of data that helps decide</p>
                    <p><strong>p-value:</strong> Probability of observing data this extreme if H‚ÇÄ is true</p>
                    <p><strong>Decision rule:</strong> Reject H‚ÇÄ if p-value < Œ± (significance level)</p>
                </div>

                <div class="property-grid">
                    <div class="property-card">
                        <h5>‚ùå Type I Error</h5>
                        <p>Reject H‚ÇÄ when it's true</p>
                        <p><strong>Probability:</strong> Œ± (significance level)</p>
                        <p><strong>Example:</strong> False positive in medical test</p>
                    </div>
                    <div class="property-card">
                        <h5>‚ùå Type II Error</h5>
                        <p>Fail to reject H‚ÇÄ when it's false</p>
                        <p><strong>Probability:</strong> Œ≤</p>
                        <p><strong>Power:</strong> 1 - Œ≤ (probability of correctly rejecting H‚ÇÄ)</p>
                    </div>
                </div>

                <table class="comparison-table">
                    <tr>
                        <th>Reality / Decision</th>
                        <th>Reject H‚ÇÄ</th>
                        <th>Fail to Reject H‚ÇÄ</th>
                    </tr>
                    <tr>
                        <td><strong>H‚ÇÄ True</strong></td>
                        <td style="background: #ffebee;">Type I Error (Œ±)</td>
                        <td style="background: #e8f5e8;">Correct Decision</td>
                    </tr>
                    <tr>
                        <td><strong>H‚ÇÅ True</strong></td>
                        <td style="background: #e8f5e8;">Correct Decision (Power)</td>
                        <td style="background: #ffebee;">Type II Error (Œ≤)</td>
                    </tr>
                </table>
            </div>

            <div class="section">
                <h2>üîß Computational Methods</h2>

                <div class="property-grid">
                    <div class="method-card">
                        <h4>üéØ Newton-Raphson</h4>
                        <p><strong>For finding MLEs when no closed form exists</strong></p>
                        <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                            Œ∏‚ÅΩ·µè‚Å∫¬π‚Åæ = Œ∏‚ÅΩ·µè‚Åæ - H‚Åª¬π(Œ∏‚ÅΩ·µè‚Åæ)S(Œ∏‚ÅΩ·µè‚Åæ)
                        </div>
                        <p>where S is score function, H is Hessian</p>
                        <p><strong>Advantage:</strong> Quadratic convergence</p>
                        <p><strong>Issue:</strong> May not converge if starting point is poor</p>
                    </div>

                    <div class="method-card">
                        <h4>üìä EM Algorithm</h4>
                        <p><strong>For models with missing/latent data</strong></p>
                        <div class="bootstrap-step">
                            <strong>E-step:</strong> Compute Q(Œ∏|Œ∏‚ÅΩ·µè‚Åæ) = E[log L(Œ∏|X,Z)|X,Œ∏‚ÅΩ·µè‚Åæ]
                        </div>
                        <div class="bootstrap-step">
                            <strong>M-step:</strong> Œ∏‚ÅΩ·µè‚Å∫¬π‚Åæ = argmax Q(Œ∏|Œ∏‚ÅΩ·µè‚Åæ)
                        </div>
                        <p><strong>Examples:</strong> Mixture models, factor analysis, HMMs</p>
                        <p><strong>Guarantee:</strong> Likelihood increases at each step</p>
                    </div>
                </div>
            </div>

            <div class="section">
                <h2>‚ö†Ô∏è Common Pitfalls</h2>

                <div class="property-grid">
                    <div class="theorem-box" style="background: linear-gradient(135deg, #ff6b6b 0%, #ee5a6f 100%);">
                        <h4>‚ùå Confusing estimator and estimate</h4>
                        <p><strong>Estimator:</strong> Random variable (function of data)</p>
                        <p><strong>Estimate:</strong> Realized value for specific dataset</p>
                        <p><strong>Example:</strong> XÃÑ is estimator, xÃÑ = 5.2 is estimate</p>
                    </div>

                    <div class="theorem-box" style="background: linear-gradient(135deg, #ff6b6b 0%, #ee5a6f 100%);">
                        <h4>‚ùå Misinterpreting confidence intervals</h4>
                        <p><strong>Wrong:</strong> "95% probability parameter is in this interval"</p>
                        <p><strong>Right:</strong> "95% of such intervals contain the parameter"</p>
                        <p><strong>Key:</strong> Interval is random, parameter is fixed!</p>
                    </div>

                    <div class="theorem-box" style="background: linear-gradient(135deg, #ff6b6b 0%, #ee5a6f 100%);">
                        <h4>‚ùå Ignoring bias-variance tradeoff</h4>
                        <p><strong>MSE = Bias¬≤ + Variance</strong></p>
                        <p>Sometimes a slightly biased estimator with much lower variance is better!</p>
                        <p><strong>Example:</strong> Shrinkage estimators in high dimensions</p>
                    </div>

                    <div class="theorem-box" style="background: linear-gradient(135deg, #ff6b6b 0%, #ee5a6f 100%);">
                        <h4>‚ùå Applying asymptotic results too early</h4>
                        <p>Large sample properties may not hold for small n</p>
                        <p><strong>Example:</strong> MLE may be biased in small samples</p>
                        <p><strong>Solution:</strong> Check finite-sample properties when possible</p>
                    </div>
                </div>
            </div>

            <div class="section">
                <h2>üîó Looking Ahead</h2>

                <div class="example-box">
                    <h4>üöÄ What's Next?</h4>
                    <p>This chapter provided the foundation. Coming up:</p>
                    <ul>
                        <li><strong>Chapter 8:</strong> Estimating CDFs and distribution-free methods</li>
                        <li><strong>Chapter 9:</strong> Bootstrap in detail</li>
                        <li><strong>Chapter 10-11:</strong> Hypothesis testing theory and practice</li>
                        <li><strong>Chapter 12:</strong> Bayesian approach to inference</li>
                    </ul>
                    <p><strong>Key insight:</strong> Most of modern statistics builds on these fundamental concepts!</p>
                </div>

                <div class="theorem-box">
                    <h4>üéØ Big Picture</h4>
                    <p><strong>Frequentist paradigm:</strong> Parameters are fixed, data is random</p>
                    <p><strong>Goal:</strong> Find procedures with good long-run properties</p>
                    <p><strong>Tools:</strong> Unbiasedness, consistency, efficiency, coverage probability</p>
                    <p><strong>Philosophy:</strong> "What would happen if we repeated this many times?"</p>
                </div>
            </div>
        </div>

        <div class="nav-buttons">
            <a href="#" class="nav-btn">‚Üê Chapter 6: Convergence</a>
            <a href="#" class="nav-btn">Chapter 8: CDF Estimation ‚Üí</a>
        </div>
    </div>
</body>
</html>