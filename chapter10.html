<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter 10: Parametric Inference</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 50%, #667eea 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: rgba(255, 255, 255, 0.95);
            border-radius: 20px;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.15);
            overflow: hidden;
        }

        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 40px;
            text-align: center;
            position: relative;
            overflow: hidden;
        }

        .header::before {
            content: 'üéØüìäŒ∏‚ö°üîç';
            position: absolute;
            top: 50%;
            left: -25%;
            transform: translateY(-50%);
            font-size: 4em;
            opacity: 0.1;
            animation: estimate 15s ease-in-out infinite;
        }

        @keyframes estimate {
            0%, 100% { left: -25%; transform: translateY(-50%) rotate(0deg); }
            50% { left: 125%; transform: translateY(-50%) rotate(360deg); }
        }

        .header h1 {
            position: relative;
            z-index: 1;
            font-size: 3em;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
        }

        .header p {
            position: relative;
            z-index: 1;
            font-size: 1.2em;
            opacity: 0.9;
        }

        .content {
            padding: 40px;
        }

        .section {
            margin-bottom: 40px;
            padding: 30px;
            border-radius: 15px;
            background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%);
            border-left: 5px solid #667eea;
            transition: all 0.3s ease;
            position: relative;
            overflow: hidden;
        }

        .section h2 {
            color: #2c3e50;
            font-size: 2em;
            margin-bottom: 20px;
            border-bottom: 3px solid #667eea;
            padding-bottom: 10px;
            display: inline-block;
        }

        .est-box {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            border-radius: 15px;
            margin: 25px 0;
            box-shadow: 0 15px 30px rgba(102, 126, 234, 0.3);
            text-align: center;
        }

        .theorem-box {
            background: linear-gradient(135deg, #96fbc4 0%, #f9f871 100%);
            padding: 25px;
            border-radius: 15px;
            margin: 15px 0;
            border: 2px solid #27ae60;
            box-shadow: 0 8px 20px rgba(39, 174, 96, 0.2);
            color: #2c3e50;
        }

        .formula-box {
            background: linear-gradient(135deg, #ffecd2 0%, #fcb69f 100%);
            padding: 20px;
            border-radius: 15px;
            margin: 15px 0;
            border: 2px solid #f39c12;
            font-family: 'Courier New', monospace;
            font-size: 1.1em;
            box-shadow: 0 8px 20px rgba(243, 156, 18, 0.2);
        }

        .example-box {
            background: linear-gradient(135deg, #e0c3fc 0%, #9bb5ff 100%);
            padding: 25px;
            border-radius: 15px;
            margin: 15px 0;
            border: 2px solid #9c88ff;
            box-shadow: 0 8px 20px rgba(156, 136, 255, 0.2);
        }

        .model-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .model-card {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 25px;
            border-radius: 15px;
            box-shadow: 0 10px 25px rgba(102, 126, 234, 0.3);
            transition: all 0.3s ease;
        }

        .model-card:hover {
            transform: scale(1.02);
            box-shadow: 0 15px 30px rgba(102, 126, 234, 0.4);
        }

        .warning-card {
            background: linear-gradient(135deg, #ff6b6b 0%, #ee5a6f 100%);
        }

        .nav-buttons {
            display: flex;
            justify-content: space-between;
            padding: 30px 40px;
            background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%);
        }

        .nav-btn {
            padding: 12px 25px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            text-decoration: none;
            border-radius: 25px;
            font-weight: bold;
            transition: all 0.3s ease;
            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.3);
        }

        .nav-btn:hover {
            transform: translateY(-3px);
            box-shadow: 0 8px 20px rgba(102, 126, 234, 0.4);
        }

        table {
            width: 100%; 
            border-collapse: collapse; 
            background: white; 
            border-radius: 10px; 
            overflow: hidden;
        }

        th {
            padding: 15px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }

        td {
            padding: 12px; 
            border-bottom: 1px solid #eee;
        }

        tr:nth-child(even) {
            background: #f8f9fa;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>Chapter 10: Parametric Inference</h1>
            <p>Estimating Parameters from Known Distribution Families</p>
        </div>

        <div class="content">
            <div class="section">
                <h2>üéØ What is Parametric Inference?</h2>
                
                <div class="est-box">
                    <h4>üìä The Parametric Approach</h4>
                    <p><strong>Assumption:</strong> Data comes from known family with unknown parameters</p>
                    <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                        X‚ÇÅ, X‚ÇÇ, ..., X‚Çô ~ f(x; Œ∏) where Œ∏ ‚àà Œò is unknown
                    </div>
                    <p><strong>Goal:</strong> Use data to learn about Œ∏</p>
                </div>

                <div class="model-grid">
                    <div class="model-card">
                        <h5>‚úÖ Advantages</h5>
                        <ul>
                            <li><strong>Efficiency:</strong> Use distributional information</li>
                            <li><strong>Interpretability:</strong> Parameters have meaning</li>
                            <li><strong>Theory:</strong> Well-developed asymptotic theory</li>
                            <li><strong>Inference:</strong> Confidence intervals, tests</li>
                        </ul>
                    </div>

                    <div class="model-card">
                        <h5>‚ö†Ô∏è Disadvantages</h5>
                        <ul>
                            <li><strong>Model dependence:</strong> Wrong family = wrong inference</li>
                            <li><strong>Restrictive:</strong> Limited to parametric families</li>
                            <li><strong>Sensitivity:</strong> Outliers can affect results</li>
                            <li><strong>Validation:</strong> Need to check model assumptions</li>
                        </ul>
                    </div>
                </div>

                <div class="example-box">
                    <h4>üìà Common Examples</h4>
                    <div class="formula-box">
                        <strong>Normal:</strong> X ~ N(Œº, œÉ¬≤), estimate Œº and œÉ¬≤
                        <br><strong>Exponential:</strong> X ~ Exp(Œª), estimate Œª
                        <br><strong>Binomial:</strong> X ~ Bin(n, p), estimate p
                        <br><strong>Poisson:</strong> X ~ Pois(Œª), estimate Œª
                    </div>
                </div>
            </div>

            <div class="section">
                <h2>üìä Method of Moments</h2>

                <div class="est-box">
                    <h4>üéØ Equate Sample and Population Moments</h4>
                    <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                        (1/n)‚àëX·µ¢·µè = E[X·µè] for k = 1, 2, ..., p
                    </div>
                    <p><strong>Strategy:</strong> Set sample moments equal to theoretical moments</p>
                </div>

                <div class="model-grid">
                    <div class="model-card">
                        <h5>‚ö° Algorithm</h5>
                        <ol>
                            <li><strong>Express moments in terms of parameters:</strong> E[X], E[X¬≤], ...</li>
                            <li><strong>Compute sample moments:</strong> XÃÑ, (1/n)‚àëX·µ¢¬≤, ...</li>
                            <li><strong>Set equal and solve:</strong> System of equations</li>
                            <li><strong>Get estimators:</strong> Œ∏ÃÇ‚ÇÅ, Œ∏ÃÇ‚ÇÇ, ...</li>
                        </ol>
                    </div>

                    <div class="model-card">
                        <h5>üìà Properties</h5>
                        <ul>
                            <li><strong>Consistent:</strong> Œ∏ÃÇ‚Çô ‚Üí·µñ Œ∏ as n ‚Üí ‚àû</li>
                            <li><strong>Asymptotically normal:</strong> ‚àön(Œ∏ÃÇ‚Çô - Œ∏) ‚Üí·µà N(0,V)</li>
                            <li><strong>Simple:</strong> Easy to compute</li>
                            <li><strong>General:</strong> Works for any distribution</li>
                        </ul>
                    </div>
                </div>

                <div class="example-box">
                    <h4>üìä Example: Normal Distribution</h4>
                    <p><strong>Parameters:</strong> Œº and œÉ¬≤</p>
                    <div class="formula-box">
                        <strong>First moment:</strong> E[X] = Œº ‚üπ ŒºÃÇ = XÃÑ
                        <br><strong>Second moment:</strong> E[X¬≤] = Œº¬≤ + œÉ¬≤ ‚üπ œÉÃÇ¬≤ = (1/n)‚àëX·µ¢¬≤ - XÃÑ¬≤
                        <br><strong>Alternative:</strong> œÉÃÇ¬≤ = (1/n)‚àë(X·µ¢ - XÃÑ)¬≤
                    </div>
                </div>
            </div>

            <div class="section">
                <h2>‚ö° Maximum Likelihood Estimation</h2>

                <div class="est-box">
                    <h4>üéØ Choose Œ∏ That Makes Data Most Likely</h4>
                    <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                        L(Œ∏) = ‚àè·µ¢‚Çå‚ÇÅ‚Åø f(x·µ¢; Œ∏)
                        <br>Œ∏ÃÇ‚Çò‚Çó‚Çë = argmax L(Œ∏)
                    </div>
                    <p><strong>Intuition:</strong> What parameter value makes the observed data most probable?</p>
                </div>

                <div class="model-grid">
                    <div class="model-card">
                        <h5>üìä Log-Likelihood</h5>
                        <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                            ‚Ñì(Œ∏) = log L(Œ∏) = ‚àë·µ¢‚Çå‚ÇÅ‚Åø log f(x·µ¢; Œ∏)
                        </div>
                        <p><strong>Easier to work with:</strong> Sums instead of products</p>
                        <p><strong>Same maximum:</strong> log is monotonic</p>
                    </div>

                    <div class="model-card">
                        <h5>üßÆ Finding MLE</h5>
                        <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                            d‚Ñì/dŒ∏ = 0 (first-order condition)
                            <br>d¬≤‚Ñì/dŒ∏¬≤ < 0 (second-order condition)
                        </div>
                        <p><strong>Score function:</strong> S(Œ∏) = d‚Ñì/dŒ∏</p>
                        <p><strong>MLE satisfies:</strong> S(Œ∏ÃÇ) = 0</p>
                    </div>
                </div>

                <div class="theorem-box">
                    <h4>‚ö° Properties of MLE</h4>
                    <p><strong>Under regularity conditions:</strong></p>
                    <div class="formula-box">
                        1. Consistency: Œ∏ÃÇ‚Çô ‚Üí·µñ Œ∏
                        <br>2. Asymptotic normality: ‚àön(Œ∏ÃÇ‚Çô - Œ∏) ‚Üí·µà N(0, I(Œ∏)‚Åª¬π)
                        <br>3. Invariance: If Œ∑ = g(Œ∏), then Œ∑ÃÇ = g(Œ∏ÃÇ)
                        <br>4. Efficiency: Achieves Cram√©r-Rao lower bound asymptotically
                    </div>
                </div>

                <div class="example-box">
                    <h4>üìà Example: Exponential Distribution</h4>
                    <p><strong>PDF:</strong> f(x; Œª) = Œªe‚ÅªŒªÀ£ for x ‚â• 0</p>
                    <div class="formula-box">
                        <strong>Log-likelihood:</strong> ‚Ñì(Œª) = n log Œª - Œª‚àëx·µ¢
                        <br><strong>Score:</strong> S(Œª) = n/Œª - ‚àëx·µ¢
                        <br><strong>Setting S(Œª) = 0:</strong> ŒªÃÇ = n/‚àëx·µ¢ = 1/XÃÑ
                    </div>
                    <p><strong>Result:</strong> MLE is reciprocal of sample mean</p>
                </div>
            </div>

            <div class="section">
                <h2>üìä Fisher Information</h2>

                <div class="est-box">
                    <h4>üéØ Measuring Information About Parameters</h4>
                    <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                        I(Œ∏) = E[(‚àÇlog f/‚àÇŒ∏)¬≤] = -E[‚àÇ¬≤log f/‚àÇŒ∏¬≤]
                    </div>
                    <p><strong>Interpretation:</strong> How much information data provides about Œ∏</p>
                </div>

                <div class="model-grid">
                    <div class="model-card">
                        <h5>üìà Observed Information</h5>
                        <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                            I‚Çí·µ¶‚Çõ(Œ∏) = -‚àÇ¬≤‚Ñì/‚àÇŒ∏¬≤
                        </div>
                        <p><strong>Sample-based version of Fisher information</strong></p>
                        <p><strong>Used for:</strong> Standard error estimation</p>
                    </div>

                    <div class="model-card">
                        <h5>‚ö° Cram√©r-Rao Bound</h5>
                        <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                            Var(Œ∏ÃÇ) ‚â• 1/(nI(Œ∏))
                        </div>
                        <p><strong>Lower bound on variance of unbiased estimators</strong></p>
                        <p><strong>Efficient estimators:</strong> Achieve the bound</p>
                    </div>
                </div>

                <div class="example-box">
                    <h4>üìä Standard Errors from Fisher Information</h4>
                    <div class="formula-box">
                        <strong>Asymptotic variance:</strong> Var(Œ∏ÃÇ) ‚âà 1/(nI(Œ∏))
                        <br><strong>Standard error:</strong> SE(Œ∏ÃÇ) ‚âà 1/‚àö(nI(Œ∏ÃÇ))
                        <br><strong>Using observed info:</strong> SE(Œ∏ÃÇ) ‚âà 1/‚àöI‚Çí·µ¶‚Çõ(Œ∏ÃÇ)
                    </div>
                </div>
            </div>

            <div class="section">
                <h2>üîß Computational Methods</h2>

                <div class="model-grid">
                    <div class="model-card">
                        <h5>üéØ Newton-Raphson</h5>
                        <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                            Œ∏‚ÅΩ·µè‚Å∫¬π‚Åæ = Œ∏‚ÅΩ·µè‚Åæ - [H‚Çñ]‚Åª¬πS‚Çñ
                        </div>
                        <p><strong>S‚Çñ:</strong> Score at Œ∏‚ÅΩ·µè‚Åæ</p>
                        <p><strong>H‚Çñ:</strong> Hessian at Œ∏‚ÅΩ·µè‚Åæ</p>
                        <p><strong>Fast convergence near solution</strong></p>
                    </div>

                    <div class="model-card">
                        <h5>üìà Gradient Methods</h5>
                        <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                            Œ∏‚ÅΩ·µè‚Å∫¬π‚Åæ = Œ∏‚ÅΩ·µè‚Åæ + Œ±‚ÇñS‚Çñ
                        </div>
                        <p><strong>Œ±‚Çñ:</strong> Step size</p>
                        <p><strong>Simpler than Newton-Raphson</strong></p>
                        <p><strong>Slower but more stable convergence</strong></p>
                    </div>

                    <div class="model-card">
                        <h5>üîÑ EM Algorithm</h5>
                        <p><strong>For missing data/latent variables:</strong></p>
                        <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                            E-step: Q(Œ∏|Œ∏‚ÅΩ·µè‚Åæ) = E[log L(Œ∏)|X,Œ∏‚ÅΩ·µè‚Åæ]
                            <br>M-step: Œ∏‚ÅΩ·µè‚Å∫¬π‚Åæ = argmax Q(Œ∏|Œ∏‚ÅΩ·µè‚Åæ)
                        </div>
                        <p><strong>Guaranteed to increase likelihood</strong></p>
                    </div>

                    <div class="model-card">
                        <h5>‚ö° Numerical Considerations</h5>
                        <ul>
                            <li><strong>Starting values:</strong> Multiple starting points</li>
                            <li><strong>Convergence:</strong> Check tolerance criteria</li>
                            <li><strong>Boundary constraints:</strong> Handle parameter bounds</li>
                            <li><strong>Numerical stability:</strong> Watch for overflow/underflow</li>
                        </ul>
                    </div>
                </div>
            </div>

            <div class="section">
                <h2>üìä Confidence Intervals</h2>

                <div class="model-grid">
                    <div class="model-card">
                        <h5>üìà Asymptotic Normal</h5>
                        <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                            Œ∏ÃÇ ¬± z_{Œ±/2} SE(Œ∏ÃÇ)
                        </div>
                        <p><strong>Based on:</strong> ‚àön(Œ∏ÃÇ - Œ∏) ‚Üí·µà N(0, I(Œ∏)‚Åª¬π)</p>
                        <p><strong>Standard error:</strong> SE(Œ∏ÃÇ) = 1/‚àö(nI(Œ∏ÃÇ))</p>
                    </div>

                    <div class="model-card">
                        <h5>üéØ Profile Likelihood</h5>
                        <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                            {Œ∏ : 2[‚Ñì(Œ∏ÃÇ) - ‚Ñì(Œ∏)] ‚â§ œá¬≤‚ÇÅ,Œ±}
                        </div>
                        <p><strong>More accurate than Wald intervals</strong></p>
                        <p><strong>Automatically accounts for skewness</strong></p>
                    </div>
                </div>

                <div class="example-box">
                    <h4>üìä Comparison of Methods</h4>
                    <table>
                        <tr>
                            <th>Method</th>
                            <th>Formula</th>
                            <th>Pros</th>
                            <th>Cons</th>
                        </tr>
                        <tr>
                            <td><strong>Wald</strong></td>
                            <td>Œ∏ÃÇ ¬± z SE(Œ∏ÃÇ)</td>
                            <td>Simple, fast</td>
                            <td>May be inaccurate</td>
                        </tr>
                        <tr>
                            <td><strong>Profile</strong></td>
                            <td>Invert LR test</td>
                            <td>More accurate</td>
                            <td>Computationally intensive</td>
                        </tr>
                        <tr>
                            <td><strong>Bootstrap</strong></td>
                            <td>Resample data</td>
                            <td>Nonparametric</td>
                            <td>Computer intensive</td>
                        </tr>
                    </table>
                </div>
            </div>

            <div class="section">
                <h2>üßÆ Sufficient Statistics</h2>

                <div class="est-box">
                    <h4>üéØ Statistics That Contain All Information</h4>
                    <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                        T(X) is sufficient for Œ∏ if P(X|T(X), Œ∏) doesn't depend on Œ∏
                    </div>
                    <p><strong>Interpretation:</strong> T(X) contains all information about Œ∏ in the data</p>
                </div>

                <div class="theorem-box">
                    <h4>üìä Fisher-Neyman Factorization Theorem</h4>
                    <p><strong>T(X) is sufficient iff:</strong></p>
                    <div class="formula-box">
                        L(Œ∏) = g(T(x), Œ∏) √ó h(x)
                    </div>
                    <p><strong>where h(x) doesn't depend on Œ∏</strong></p>
                </div>

                <div class="model-grid">
                    <div class="model-card">
                        <h5>‚ö° Properties</h5>
                        <ul>
                            <li><strong>Data reduction:</strong> Can ignore everything except T(X)</li>
                            <li><strong>MLE:</strong> Depends only on sufficient statistic</li>
                            <li><strong>Minimal sufficiency:</strong> Smallest sufficient statistic</li>
                            <li><strong>Completeness:</strong> Additional optimality property</li>
                        </ul>
                    </div>

                    <div class="model-card">
                        <h5>üìà Examples</h5>
                        <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                            <strong>Normal(Œº,œÉ¬≤):</strong> (‚àëX·µ¢, ‚àëX·µ¢¬≤)
                            <br><strong>Exponential(Œª):</strong> ‚àëX·µ¢
                            <br><strong>Binomial(n,p):</strong> ‚àëX·µ¢
                            <br><strong>Poisson(Œª):</strong> ‚àëX·µ¢
                        </div>
                    </div>
                </div>
            </div>

            <div class="section">
                <h2>üìà Exponential Families</h2>

                <div class="est-box">
                    <h4>üéØ Unified Framework for Many Distributions</h4>
                    <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                        f(x; Œ∏) = exp{Œ∑(Œ∏)T(x) - A(Œ∏) + B(x)}
                    </div>
                    <p><strong>Many common distributions belong to exponential families</strong></p>
                </div>

                <div class="model-grid">
                    <div class="model-card">
                        <h5>üìä Canonical Form</h5>
                        <div class="formula-box" style="background: rgba(255,255,255,0.2);">
                            f(x; Œ∑) = exp{Œ∑T(x) - A(Œ∑) + B(x)}
                        </div>
                        <p><strong>Œ∑:</strong> Natural parameter</p>
                        <p><strong>T(x):</strong> Sufficient statistic</p>
                        <p><strong>A(Œ∑):</strong> Log-partition function</p>
                    </div>

                    <div class="model-card">
                        <h5>‚ö° Properties</h5>
                        <ul>
                            <li><strong>Sufficient statistic:</strong> T(x) = ‚àëT(x·µ¢)</li>
                            <li><strong>MLE:</strong> Has explicit form often</li>
                            <li><strong>Conjugate priors:</strong> Natural Bayesian analysis</li>
                            <li><strong>Moments:</strong> E[T(X)] = A'(Œ∑)</li>
                        </ul>
                    </div>
                </div>

                <div class="example-box">
                    <h4>üìä Common Exponential Family Members</h4>
                    <table>
                        <tr>
                            <th>Distribution</th>
                            <th>Œ∑(Œ∏)</th>
                            <th>T(x)</th>
                            <th>A(Œ∑)</th>
                        </tr>
                        <tr>
                            <td><strong>Normal(Œº,1)</strong></td>
                            <td>Œº</td>
                            <td>x</td>
                            <td>Œ∑¬≤/2</td>
                        </tr>
                        <tr>
                            <td><strong>Exponential(Œª)</strong></td>
                            <td>-Œª</td>
                            <td>x</td>
                            <td>-log(-Œ∑)</td>
                        </tr>
                        <tr>
                            <td><strong>Bernoulli(p)</strong></td>
                            <td>log(p/(1-p))</td>
                            <td>x</td>
                            <td>log(1+e·∂Ø)</td>
                        </tr>
                        <tr>
                            <td><strong>Poisson(Œª)</strong></td>
                            <td>log Œª</td>
                            <td>x</td>
                            <td>e·∂Ø</td>
                        </tr>
                    </table>
                </div>
            </div>

            <div class="section">
                <h2>‚ö†Ô∏è Common Pitfalls</h2>

                <div class="model-grid">
                    <div class="model-card warning-card">
                        <h5>‚ùå Model Misspecification</h5>
                        <p><strong>Problem:</strong> Wrong parametric family</p>
                        <p><strong>Consequence:</strong> Biased and inconsistent estimates</p>
                        <p><strong>Solution:</strong> Model diagnostics, goodness-of-fit tests</p>
                    </div>

                    <div class="model-card warning-card">
                        <h5>‚ùå Boundary Issues</h5>
                        <p><strong>Problem:</strong> Parameters near boundary of parameter space</p>
                        <p><strong>Example:</strong> Variance near 0, probabilities near 0 or 1</p>
                        <p><strong>Effect:</strong> Asymptotic theory may not apply</p>
                    </div>

                    <div class="model-card warning-card">
                        <h5>‚ùå Local Maxima</h5>
                        <p><strong>Problem:</strong> Likelihood may have multiple peaks</p>
                        <p><strong>Risk:</strong> Optimization finds local, not global maximum</p>
                        <p><strong>Solution:</strong> Multiple starting values, global optimization</p>
                    </div>

                    <div class="model-card warning-card">
                        <h5>‚ùå Small Sample Issues</h5>
                        <p><strong>Problem:</strong> Asymptotic approximations poor for small n</p>
                        <p><strong>Examples:</strong> MLE bias, normal approximation inaccuracy</p>
                        <p><strong>Solutions:</strong> Bias correction, exact methods, bootstrap</p>
                    </div>
                </div>
            </div>

            <div class="section">
                <h2>üîó Connections to Other Chapters</h2>

                <div class="model-grid">
                    <div class="example-box">
                        <h5>üìä To Expectation (Chapter 4)</h5>
                        <p><strong>Method of moments:</strong> Based on population moments</p>
                        <p><strong>Fisher information:</strong> Expected value of score squares</p>
                        <p><strong>Cram√©r-Rao bound:</strong> Variance lower bound</p>
                    </div>

                    <div class="example-box">
                        <h5>üéØ To Convergence (Chapter 6)</h5>
                        <p><strong>Consistency:</strong> Estimators converge to true values</p>
                        <p><strong>Asymptotic normality:</strong> Large-sample distributions</p>
                        <p><strong>Delta method:</strong> Functions of consistent estimators</p>
                    </div>

                    <div class="example-box">
                        <h5>üìà To Hypothesis Testing (Chapter 11)</h5>
                        <p><strong>Likelihood ratio tests:</strong> Based on MLE</p>
                        <p><strong>Wald tests:</strong> Based on asymptotic normality</p>
                        <p><strong>Score tests:</strong> Based on score function</p>
                    </div>

                    <div class="example-box">
                        <h5>üîÑ To Bayesian Methods (Chapter 12)</h5>
                        <p><strong>Prior specification:</strong> Conjugate priors for exponential families</p>
                        <p><strong>MAP estimation:</strong> Related to penalized MLE</p>
                        <p><strong>Asymptotic equivalence:</strong> Frequentist and Bayesian methods agree</p>
                    </div>
                </div>
            </div>
        </div>

        <div class="nav-buttons">
            <a href="#" class="nav-btn">‚Üê Chapter 9: Bootstrap</a>
            <a href="#" class="nav-btn">Chapter 11: Hypothesis Testing ‚Üí</a>
        </div>
    </div>
</body>
</html>